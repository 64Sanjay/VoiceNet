# Speaker Diarization

Speaker diarization is the process of partitioning an audio stream into segments according to the identity of the speaker. This repository provides tools and code for automatic speaker diarization â€” figuring out "who spoke when" in an audio recording.

## Features

- **Automatic Speaker Segmentation:** Splits audio into segments each corresponding to a single speaker.
- **Speaker Identification:** Assigns unique labels (Speaker 1, Speaker 2, etc.) to each speaker detected, optionally linking to known identities if available.
- **Visualization and Reporting:** Generates easy-to-read visualizations of speaker timelines.

---

## Repository Structure

```
speaker_diarization/
â”‚
â”œâ”€â”€ config/                         # Configuration files
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ data/                           # Dataset & preprocessing
â”‚   â”œâ”€â”€ aishell4/                   # AISHELL-4 dataset
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â”œâ”€â”€ segments/
â”‚   â”‚   â”‚   â””â”€â”€ segments.json
â”‚   â”‚   â”œâ”€â”€ train.txt
â”‚   â”‚   â”œâ”€â”€ train_small.txt
â”‚   â”‚   â”œâ”€â”€ train_full.txt
â”‚   â”‚   â”œâ”€â”€ val.txt
â”‚   â”‚   â”œâ”€â”€ val_small.txt
â”‚   â”‚   â”œâ”€â”€ val_full.txt
â”‚   â”‚   â””â”€â”€ test.txt
â”‚   â”œâ”€â”€ augmentation.py             # Audio augmentation
â”‚   â”œâ”€â”€ preprocessing.py            # Feature extraction & segmentation
â”‚   â”œâ”€â”€ dataset.py                  # Dataset loader
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/                         # Diarization models
â”‚   â”œâ”€â”€ diarization_model.py        # End-to-end diarization model
â”‚   â”œâ”€â”€ speaker_encoder.py          # Speaker embedding extractor
â”‚   â”œâ”€â”€ segmentation.py             # Speech segmentation model
â”‚   â”œâ”€â”€ clustering.py               # Speaker clustering logic
â”‚   â”œâ”€â”€ losses.py                   # Loss functions
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ training/                       # Training pipeline
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ evaluation/                     # Evaluation logic
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”œâ”€â”€ metrics.py                  # DER, JER, etc.
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ outputs/                        # Training outputs
â”‚   â”œâ”€â”€ diarization_*/              # Experiment runs
â”‚   â”‚   â”œâ”€â”€ best_model.pt
â”‚   â”‚   â”œâ”€â”€ checkpoint_epoch_*.pt
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ train.log
â”‚   â””â”€â”€ simple_model/
â”‚       â””â”€â”€ model.pt
â”‚
â”œâ”€â”€ demo/                           # Interactive demo
â”‚   â””â”€â”€ demo_gradio.py
â”‚
â”œâ”€â”€ utils/                          # Utility functions
â”‚   â”œâ”€â”€ audio_utils.py
â”‚   â”œâ”€â”€ rttm_utils.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/                        # Dataset scripts
â”‚   â”œâ”€â”€ download_aishell4.py
â”‚   â””â”€â”€ prepare_data.py
â”‚
â”œâ”€â”€ inference.py                    # Diarization inference
â”œâ”€â”€ evaluate.py                     # Evaluation entry script
â”œâ”€â”€ train.py                        # Training entry script
â”œâ”€â”€ fix_imports.py                  # Import fixes
â””â”€â”€ __init__.py
```

### âœ… Why this structure is ideal

- âœ” Matches your actual filesystem  
- âœ” Fully modular (data â†’ model â†’ training â†’ evaluation)  
- âœ” Research-grade diarization pipeline  
- âœ” Compatible with AISHELL-4  
- âœ” Ready for papers, thesis, and production demos  

**ğŸ” Conceptual flow (for understanding)**  
Audio â†’ Segmentation â†’ Speaker Encoder â†’ Clustering â†’ RTTM Output  

---

## Installation

Clone the repository:
```bash
git clone https://github.com/<owner>/speaker_diarization.git
cd speaker_diarization
```

Install dependencies (using pip or conda):
```bash
pip install -r requirements.txt
```

## Usage

### 1. Prepare your audio file
Place your audio file (e.g., `meeting.wav`) in the `data/` directory.

### 2. Run diarization

```bash
python diarize.py --audio data/meeting.wav --output results.json
```

### 3. View results

- Speaker segments and identities are saved to the specified output.
- Example output:
    ```json
    [
      {"speaker": "Speaker 1", "start": 0.0, "end": 15.2},
      {"speaker": "Speaker 2", "start": 15.2, "end": 30.8}
    ]
    ```

### 4. Visualization

Optionally, visualize diarization:
```bash
python visualize.py --input results.json --show
```

## Example

```python
from diarization import diarize_audio

segments = diarize_audio("data/meeting.wav")
for segment in segments:
    print(f"{segment['speaker']} spoke from {segment['start']}s to {segment['end']}s")
```

## Requirements

- Python 3.7+
- [List of specific dependencies, e.g., PyTorch, librosa, numpy]

## Model

This repository uses [mention model or algorithm, such as pyAudioAnalysis, pyannote.audio, etc.], see `model/` directory for details. You can change model settings in `config.yaml`.

## Contributing

Pull requests, issues, and feature suggestions are welcome! Please read our [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
